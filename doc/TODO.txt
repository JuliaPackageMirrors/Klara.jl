01) Add tuners based on established adaptive MCMC schemes
02 - done) Add empirical tuner for MCMC samplers
03 - done) Allow storage of gradients in runners
04 - done) Port zero-variance estimators from GeometricMCMC
05 - done) Extend MCMCLikModel constructor to allow for user-inputed evalall functions
06 - done) Split RWM according to employed tuner or wrap tuning code in tune() functions
07) Extend autodiff capabilities for MCMC samplers that need higher order derivatives
08 - done) Update README file to reflect current state of MCMC package
09) Write a user guide using LaTeX (to be placed in doc directory)
10 - done) Organize Bayesian logit and probit examples and tests better
11) Add the following samplers:
11.01 - done) Independent Metropolis Hastings (IMH)
11.02) Adaptive Metropolis (AM) by H. Haario, E. Saksman, and J. Tamminen
11.03) Adaptive Optimal Scaling Metropolis Hastings (AOSMH) by P. H. Garthwaite, Y. Fan, S. A. Sisson
11.04) Hit-And-Run Metropolis (HARM), see LaplacesDemon R package
11.05) Componentwise Hit-And-Run Metropolis (CHARM), see LaplacesDemon R package
11.06) Kernel Adaptive Metropolis-Hastings (KAM), known as MCMC Kameleon
11.07) Orientational Bias Monte Carlo (OBMC)
11.08) Split HMC (SHMC)
11.09 - done) Rao-Blackwellized HMC (RBHMC)
11.10 - done) Position-dependent MALA (PMALA)
11.11) Subsample-Adapting Langevin Algorithm (SALA)
11.12 - done) Explicit Riemannian Manifold Lagrangian Monte Carlo (eRMLMC)
11.13 - done) Semi-explicit Riemannian Manifold Lagrangian Monte Carlo (RMLMC)
11.14) Wormhole Hamiltonian Monte Carlo (WHMC)
12) Design and implement parallel population MCMC capable of running on cluster workers
13) Use BUGS approach based on graphical models to define Gibbs-based algorithms
14) EM (expectation-maximization) algorithm
15) Rejection sampling
16) Slice sampling
17) Importance sampling
18) MCMC for hierarchical models (constrained Monte Carlo)
19) Simulated annealing
20) Approximate Bayesian Computation (ABC) methods
21 - done) Implement estimators for MCMC variance, Monte Carlo error, effective sample size(ESS) and integrated
autocorrelation time
22) Implement MCMC summary statistics and MCMC convergence diagnostics that require spectral computations
23) Make algebraic changes in samplers to speed them up
